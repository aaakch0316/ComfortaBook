#### Korean Speech recognition using deep learning _ 서울대학교 논문



##### 음성인식이란

- 음성 신호(sppench signal)의 특징을 추출하여 분석하고, 이를 단어나 문장으로 변환하는 일련의처리과정

##### 딥러닝 전의 기본과정

- 기존의 음성인식 모형은 주로 음소 단위의 **음향모형**(acoustic model)과 **언어모형**(language model)으로 구성된다.
- **음향모형**은 음성 신호를 음소나 유사 음소로 변환하는 작업을 의미하며 변환된 음소들은 **렉시콘**(lexicon)과 **언어모형**에 의한 문법, 문맥에 맞는 언어로 재구성된다.

- **렉시콘**이란 음소와 이에 대응하는 단어를 기록한 사전으로서 음소 단위로 훈련되는 음향모형의 후처리를 위해 사용된다.
- 이처럼 기존의 음성인식 방식은 음성신호에서 음소, 단어, 문장 순의 복잡한 변환과정이 요구되며 음소를 비롯한 언어적 특성에 대해 많은 사전 지식을 알아야 하는 번거로움이 있었다.

##### 딥러닝(deep learning)

- 자료 입력에서 목표한 결과를 별도의 중간 매개 없이 학습하는 **종단 간(end-to-end) 학습**을 간으케 했다. 
- end-to-end 학습에서는 주어진 음성을 음소 및 형태소를 거치지 않고 바로 단어나 문장으로 변환할 수 있다. 
- 즉, 음소 단위로 훈련할 필요가 없고, 음소를 매개로 하는 중간 단계와 렉시콘 사전이 생략할 수 있어 과정이 간소화 된다.

##### 대표적인 end-to-end 모형

- **CTC 모형**(connectionist temporal classification) _ 2006
- **LAS 모형**(listen, attend, and spell) - Seq2Seq 모형의 변형인 주의 기제 모형을 음성인식에 적용한 대표적인 모형 _ 2015



##### 디코딩

- 모형의 학습과 별개로 음성 자료를 문자열로 바꾸는 디코딩
- 종류는 **빔 탐색(beam search)**과 **언어 모형(language model)**



##### 순환신경망(recurrentw neural network; RNN)

- 최신 음성인식 모형들은 순환신경망(RNN)을 기반으로 개발되고 있다.
- 순환신경망은 은닝층이 재귀적인 구조를 갖는 인공신경망이며 음성인식, 번역, 이미지 주석 생성 등 순차적인 자료 처리에 적합하다.
- 문제점) 기존 순환 신경망은 시간이 길어질수록 경사도 소실 문제(vanishing gradient problem)가 발생하기 때문에 장기 의존성(long-term dependency)을 학습시킬 수 없는 한계점이 존재한다. _ 1994
- 이러한 장기 의존성 문제를 해결하기 위해 등장한 모형이 long short-term memory(LSTM)이다. 즉, RNN은 긴문장에 대해서는 다음문장을 이해할 수 없다.
- i work at google -> 에서 명사인지 동사인지 판단하는 것을 RNN이라고 한다. 



##### LSTM(long short-term memory)

- LSTM은 기존의 뉴런을 3개의 게이트(입력/출력/망각)을 도입한 LSTM 블록으로 대체하여 장기 의존성을 학습 가능하게 해준다. _ 1997



##### GUR(gate recurrent unit)

- 2014년에 LSTM의 변형인 GRU를 제안하였다.
- GRU는 일부 게이트를 생략하고 단순하게 리셋 게이트와 갱신 게이트 만으로 구성된 모형으로 LSTM 보다 나은 성능을 보이며 계산시간이 적게 걸리는 장점이 있다.



### 딥러닝을 기반으로 한 음성 인식 모형

- 음성 자료를 잠재 변수로 변환하는 **인코더(encoder)**와 잠재 변수로 부터 문자열을 얻어내는 **디코더(decoder)**로 구성되어 있다.
- 일반적으로 음성 자료를 10-20 ms 단위의 프레임(frame)으로 나누는데, 하나의 음성 자료가 가지는 프레임의 개수를 T라고 표기하자.



글자를 문자로 만드는 과정

https://www.youtube.com/playlist?list=PLVNY1HnUlO26qqZznHVWAqjS1fWw0zqnT



##### 인공신경망 기계번역 (i love you를 한국 말로 난 널사랑해 로 만든다.)

문제_ 문장구조가 다름

문제_문장에 들어있는 단어의 수가 다름

- 시권스 투 시퀀스 모델
  - RNN을 활용해서 Encoder(단어를 순차적으로 받음)로 'I love you' 순서대로 인지하고 context vector(문맥벡터)를 통하한 후에 Decoder(기계번역을 한다)로 한국말 순서로 RNN을 활용하여 배열한다.
  - 단어의 사이즈가 적을 때는 문제가 없는데 많아질 수 록 문제가 된다.
- 에텐션 메커니즘
  - 시퀀스 투 시퀀스 모델에서 발전한 형태이다. 



##### Word2Vec

단어를 숫자로 표현하는 것이다.

비슷한 단어일 수록 2차원 평면에 비슷한 위치에 존재한다.

ex) coffee(1, 4), cafe(1, 3), soccer(5, 2), footbal(5, 2)




